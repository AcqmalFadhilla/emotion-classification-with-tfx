{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:07:53.147725Z",
     "start_time": "2024-12-21T12:07:46.557288Z"
    }
   },
   "source": [
    "import requests\n",
    "import tensorflow as tf\n",
    "import base64\n",
    "import nltk\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from pprint import PrettyPrinter\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/acqmallatief/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/acqmallatief/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:08:05.148241Z",
     "start_time": "2024-12-21T12:08:05.133485Z"
    }
   },
   "source": [
    "stemmer = PorterStemmer()\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'www\\.\\S+', '', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    cleaned_tokens = [stemmer.stem(token) for token in tokens if token not in stop_words]\n",
    "    cleaned_text = ' '.join(cleaned_tokens)\n",
    "    return cleaned_text\n",
    "\n",
    "def _bytes_feature(value):\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize_text(text):\n",
    "    example = tf.train.Example(features=tf.train.Features(feature={\n",
    "        'text': _bytes_feature(text)\n",
    "        }))\n",
    "    serialized_example = example.SerializeToString()\n",
    "    return serialized_example"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:09:40.567646Z",
     "start_time": "2024-12-21T12:09:40.559525Z"
    }
   },
   "source": [
    "end_point = os.getenv(\"API_PREDICTION\")\n",
    "\n",
    "def predict(input):\n",
    "    text = clean_text(input)\n",
    "    text = text.encode('utf-8')\n",
    "    example = serialize_text(text)\n",
    "    json_data = {\n",
    "        \"signature_name\":\"serving_default\",\n",
    "        \"instances\":[\n",
    "            {\n",
    "                \"examples\":{\"b64\": base64.b64encode(example).decode('utf-8')}\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    response = requests.post(end_point, json=json_data)\n",
    "    prediction = tf.argmax(response.json()[\"predictions\"][0]).numpy()\n",
    "    map_labels = {0: \"sadness\",\n",
    "                  1: \"joy\",\n",
    "                  2: \"love\",\n",
    "                  3: \"anger\",\n",
    "                  4: \"fear\",\n",
    "                  5: \"surprise\"}\n",
    "    return map_labels[prediction]"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T12:09:50.575113Z",
     "start_time": "2024-12-21T12:09:41.437958Z"
    }
   },
   "source": [
    "text = input(\"masukkan kalimat:\")\n",
    "\n",
    "print(f\"{text}\\n classifisi:{predict(text)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i am happy\n",
      " classifisi:joy\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
